{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何在多GPU上运行Keras模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们建议使用 TensorFlow 后端来执行这项任务。有两种方法可在多个 GPU 上运行单个模型：\n",
    "* 数据并行\n",
    "* 设备并行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在大多数情况下，　你最需要的是数据并行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据并行\n",
    "数据并行包括在每个设备上复制一次目标模型，并使用每个模型副本处理不同部分的输入数据。Keras 有一个内置的实用函数 keras.utils.multi_gpu_model，它可以生成任何模型的数据并行版本，在多达 8 个 GPU 上实现准线性加速。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将model复制到８个GPU上\n",
    "# 假定你的机器上有８个GPU可以用\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop')\n",
    "\n",
    "# 这个fit将调用在８个GPU上\n",
    "# 由于batch_size为２５６，每个GPU将处理３２个样本\n",
    "parallel_model.fit(x, y, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设备并行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设备并行性包括在不同设备上运行同一模型的不同部分。对于具有并行体系结构的模型，例如有两个分支的模型，　这种方式很合适。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# 模型中共享的 LSTM 用于并行编码两个不同的序列\n",
    "input_a = keras.Input(shape=(140, 256))\n",
    "input_b = keras.Input(shape=(140, 256))\n",
    "\n",
    "shared_lstm = keras.layers.LSTM(64)\n",
    "\n",
    "# 在一个 GPU 上处理第一个序列\n",
    "with tf.device('/gpu:0'):\n",
    "    encoded_a = shared_lstm(tweet_a)\n",
    "# 在另一个 GPU上 处理下一个序列\n",
    "with tf.device('/gpu:1'):\n",
    "    encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "# 在 CPU 上连接结果\n",
    "with tf.device_scope('/cpu:0'):\n",
    "    merged_vector = keras.layers.concatenate([encoded_a, encoded_b],\n",
    "                                             axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
