{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始使用Keras函数式API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras函数式API是定义复杂模型（如多输出模型，有向无环图，或具有共享层的模型）的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全链接网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential模型可能是实现这种网络的一个更好选择，但这个例子能帮助我们进行一些简单的理解。\n",
    "* 网络层的实例是可调用的，它以张量为参数，并且返回一个张量\n",
    "* 输入输出均为张量，它们都可以用来定义一个模型(Model)\n",
    "* 这样的模型同Keras的Sequential模型一样，都可以被训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　这部分返回一个张量\n",
    "inputs = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 层的实例是可调用的，它以张量为参数，并且返回一个张量\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　这部分创建了一个包含输入层和三个全连接层的模型\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# model.fit(data, label) #开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所有的模型都可调用，就像网络层一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用函数式API，可以轻易地重用训练好的模型：可以将任何模型看做是一个层，然后通过传递一个张量来调用它。注意，在调用模型时，不仅重用模型的结构，还重用了它的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(784,))\n",
    "# 这是可行的，并且返回上面定义的10-way softmax\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方式能允许我们快速创建可以处理序列输入的模型。只需要一行代码，你就将图像分类模型转换为视频分类模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入张量是２０个时间步的序列\n",
    "# 每一个时间为一个７８４维的向量\n",
    "\n",
    "input_sequences = Input(shape=(20, 784))\n",
    "\n",
    "# 这部分将我们之前定义的模型应用于输入序列中的每个时间步\n",
    "# 之前定义的模型的输出是一个１０-way　softmax,\n",
    "# 因而下面的层的输出将是维度为１０的２０个向量的序列\n",
    "\n",
    "processed_sequences = TimeDistributed(model)(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输入多输出模型\n",
    "以下是函数式API的一个很好的例子：具有多个输入和输出的模型。函数式API使处理大量交织的数据流变得容易。\n",
    "来考虑下面的模型。我们试图预测Twitter上的一条新闻标题有多少转发和点赞数。模型的主要输入将是新闻标题本省，即一系列词语，但是为了增添趣味。我们的模型还添加了其他的辅助输入来接收额外的数据，例如新闻标题的发布时间等。该模型也将通过两个损失函数进行监督学习。较早地在模型中使用主损失函数，是深度学习模型的一个良好正则方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要输入接收新闻标题本身，即一个整数序列（每个整数编码一个词）。 这些整数在 1 到 10,000 之间（10,000 个词的词汇表），且序列长度为 100 个词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标题输入：接收一个含有１００个整数的序列，每个整数在１到１００００之间\n",
    "# 注意，通过传递一个\"name\" 参数来命名任何层\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# Embedding 层将输入序列编码为一个稠密向量的序列\n",
    "# 每个向量维度为５１２\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# ＬＳＴＭ层把向量序列转换成单个向量\n",
    "# 它包含整个序列的上下文信息\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们插入辅助损失，使得即使在模型主损失很高的情况下，LSTM层和Embedding层能被平稳地训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 堆叠多个全连接网络层\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# 最后添加主要的逻辑回归\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在编译模型，并给辅助损失分配一个０．２的权重。如果要为不同的输出指定不同的loss_weight或loss，可以使用列表或字典。在这里，我们给loss参数传递单个损失函数，这个损失将用于所有输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "             loss_weight=[1., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([headline_data, additional_data], [labels, labels],\n",
    "#          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# # 然后使用以下方式训练：\n",
    "# model.fit({'main_input': headline_data, 'aux_input': additional_data},\n",
    "#           {'main_output': labels, 'aux_output': labels},\n",
    "#           epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
