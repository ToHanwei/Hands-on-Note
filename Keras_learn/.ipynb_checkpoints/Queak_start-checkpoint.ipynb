{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tutorial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queak start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 的核心是数据结构是model, 一种组织网络层的方式。最简单的模型是Sequential顺序模型，它由多个网络层线性堆叠。对于复杂的结构，你应该使用Keras函数式API，它允许构建任意的神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train_on_batch(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = model.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始使用Keras Sequential顺序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述的模型可以这样搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定输入数据的尺寸\n",
    "模型需要知道它期望的输入尺寸。处于这个原因，顺序模型中的第一层（且只有第一层，因为下面的层可以自动的推算尺寸）需要接受关于其尺寸的信息。有几种方法来做到这一点：\n",
    "* 传递一个input_shape参数给第一层。它是一个表示尺寸的元组（一个由整数或None组成的元组，其中None表示可能为任何正整数）。在input_shape中不包含数据的batch大小。\n",
    "* 某些2D层， 例如Dense， 支持通过参数input_dim指定输入尺寸， 某些3D时序层支持input_dim和input_length参数。\n",
    "* 如果你需要为你的输入指定一个固定的batch大小（这对stateful RNNs很有用）你可以传递一个batch_size参数给一个层。如果你同时将batch_size=32和input_shape=(6, 8)传递给一个层，那么每一批输入的尺寸就为(32, 6, 8)\n",
    "\n",
    "因此，下面的代码片段是等价的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型编译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练模型之前，你需要配置学习过程， 这是通过compile方法完成的。它接收三个参数：\n",
    "* 优化器 optimizer。它可以是现有优化器的字符串标识符，如rmsprop或adagrad，也可以是Optimizer类的实例。详见：optimizers\n",
    "* 损失函数loss， 模型试图最小化的目标函数。他可以是现有损失函数的字符串标识符， 如categorical_crossentropy或mse，也可以是一个目标函数，详见：losses。\n",
    "* 评估标准 metrics。对于任何分类问题，你都希望其值设置为metrics= ['auccuracy']。评估标准可以是现有的标准的字符串标识符，也可以是自定义的评估标准函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#均方误差回归问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义评估标准函数\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "Keras 模型在输入数据和标签的 Numpy 矩阵上进行训练。为了训练一个模型，你通常会使用 fit 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于具有2个类的单输入模型（二进制分类）\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成虚拟数据\n",
    "import keras\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "#将标签转换为分类的one-hot编码\n",
    "# one_hot_labels = keras.utils.to_categorical(labels, num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.5101 - accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.5072 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.5048 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.5023 - accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.5011 - accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.4991 - accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.4977 - accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.4967 - accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.4947 - accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.4933 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x148a6684add8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型， 以32个样本为一个batch 进行迭代\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hanwei/soft/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 694us/step - loss: 2.3411 - accuracy: 0.1010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.3136 - accuracy: 0.0980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.3029 - accuracy: 0.1010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.2924 - accuracy: 0.1150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 2.2825 - accuracy: 0.1140\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 2.2747 - accuracy: 0.1260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.2645 - accuracy: 0.1340\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.2581 - accuracy: 0.1370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 2.2481 - accuracy: 0.1530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.2357 - accuracy: 0.1540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x148a6626ba90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于具有 10 个类的单输入模型（多分类分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# 将标签转换为分类的 one-hot 编码\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知器（MLP）的softmax多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成虚拟数据\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Dense(64)是一个具有６４个隐藏神经元的全连接层\n",
    "#在第一层必须指定所期望的输入数据尺寸\n",
    "#在这里，是一个２０维的向量\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(20,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 2.3703 - accuracy: 0.1130\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 2.3519 - accuracy: 0.1060\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3377 - accuracy: 0.1050\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.3268 - accuracy: 0.0960\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3231 - accuracy: 0.1060\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.3121 - accuracy: 0.0880\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3132 - accuracy: 0.1090\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 2.3053 - accuracy: 0.1110\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3072 - accuracy: 0.1130\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 2.3041 - accuracy: 0.1160\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.2960 - accuracy: 0.1120\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.2991 - accuracy: 0.1110\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 2.2966 - accuracy: 0.1230\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.2996 - accuracy: 0.1300\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3010 - accuracy: 0.1060\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.2995 - accuracy: 0.1270\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3007 - accuracy: 0.1170\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.2944 - accuracy: 0.1130\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 2.3011 - accuracy: 0.1180\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.2969 - accuracy: 0.1240\n",
      "100/100 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20,\n",
    "         batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.313666582107544, 0.07999999821186066]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类似ＶＧＧ的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成虚拟数据\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hanwei/soft/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 输入：３通道　100＊100像素图像　-> （100, 100, 3）\n",
    "# 使用３２个大小为３＊３的卷积滤波器\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "agd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.3544\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2.3189\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2.2956\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 2.2891\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 2.2894\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 2.2865\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.2782\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 2.2986\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 2.2839\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 2.2818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x148a5e36afd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3199992179870605"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于LSTM分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=32, epochs=64)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于１D卷积的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 64\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于栈式LSTM的序列分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个模型中，　我们将３个LSTM层叠在一起，是模型能够学习更高层次的时间表示。前两个LSTM返回完整的输出序列，但最后一个只返回序列的最后一步。从而降低时间维度（将输入序列转换为单个向量）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期望输入数据尺寸：（batch_size, timesteps, data_dim\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "              input_shape=(timesteps, data_dim))) # 返回维度为３２的向量序列\n",
    "model.add(LSTM(32, return_sequences=True,))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hanwei/soft/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 12.1383 - accuracy: 0.0920 - val_loss: 13.4040 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 397us/step - loss: 13.8244 - accuracy: 0.0990 - val_loss: 14.2699 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 391us/step - loss: 14.2344 - accuracy: 0.0990 - val_loss: 14.3865 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 385us/step - loss: 14.3117 - accuracy: 0.0990 - val_loss: 14.3864 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 416us/step - loss: 14.3068 - accuracy: 0.0990 - val_loss: 14.3821 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14c31508cc88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=5,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stateful渲染的栈式LSTM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有状态(stateful)的循环神经网络模型中，　在一个batch的样本处理完成后，其内部状态（记忆）会被记录并作为下一个batch的样本初始状态。这允许处理更长的序列，同时保持计算复杂度的可控性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期望输入的尺寸：(batch_size,timesteps, data_dim)\n",
    "# 请注意，　我们必须提供完整的batch_input_shape, 因为网络是有状态的\n",
    "# 第K批数据的第i个样本是第k-1批数据的第i个样本的后续\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "              batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 96 samples\n",
      "Epoch 1/5\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 11.5951 - accuracy: 0.1375 - val_loss: 12.1918 - val_accuracy: 0.0208\n",
      "Epoch 2/5\n",
      "320/320 [==============================] - 0s 668us/step - loss: 12.4605 - accuracy: 0.0812 - val_loss: 12.7295 - val_accuracy: 0.0625\n",
      "Epoch 3/5\n",
      "320/320 [==============================] - 0s 649us/step - loss: 12.8015 - accuracy: 0.0812 - val_loss: 12.8982 - val_accuracy: 0.0625\n",
      "Epoch 4/5\n",
      "320/320 [==============================] - 0s 654us/step - loss: 12.9195 - accuracy: 0.0812 - val_loss: 12.9718 - val_accuracy: 0.0625\n",
      "Epoch 5/5\n",
      "320/320 [==============================] - 0s 622us/step - loss: 12.9729 - accuracy: 0.0812 - val_loss: 13.0085 - val_accuracy: 0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14c304d349e8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size,\n",
    "          epochs=5, shuffle=False, validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
